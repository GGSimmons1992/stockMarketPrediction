import warnings
warnings.filterwarnings('ignore')
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor as rf
from sklearn.model_selection import train_test_split
import sklearn.model_selection as ms
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

import sys
sys.path.insert(0, "../src/")
import util as util

%autosave 5


removalColumns = ["Date","Name","Close"]
rThreshold = .022





data = util.loadData("S&P").fillna(0)
dataWithDates = data.copy()
data = data.drop(removalColumns,axis=1)
allData = data.copy()

y = data["Next10DayReturn"]
X = data.drop("Next10DayReturn",axis=1)
XTrain,XTest,yTrain,yTest = train_test_split(X,y,test_size=0.2,random_state=42)

significantColumns = util.retriveLowPValueColumns(XTrain,yTrain)
XTrain,XTest = XTrain[significantColumns],XTest[significantColumns]
thresholdCorrelationColumns = util.retrieveThresholdCorrelationColumns(XTrain,yTrain,rThreshold)
XTrain,XTest = XTrain[thresholdCorrelationColumns],XTest[thresholdCorrelationColumns]

modelGridSearch = util.getBestModel(XTrain,yTrain)

util.printMSE(modelGridSearch,XTrain,XTest,yTrain,yTest)

importanceDF = util.createImportanceDF(modelGridSearch.best_estimator_.feature_importances_,XTrain.columns)

print(importanceDF.head(10))
importanceDF.head(10).plot.barh(x="columns", y="featureImportanceScores", rot=0)
util.displayScatterOfTop10Features(data,importanceDF)





data = util.loadData("NASDAQ").fillna(0)
dataWithDates = data.copy()
data = data.drop(removalColumns,axis=1)
allData = pd.concat([allData,data.copy()])

y = data["Next10DayReturn"]
X = data.drop("Next10DayReturn",axis=1)
XTrain,XTest,yTrain,yTest = train_test_split(X,y,test_size=0.2,random_state=42)

significantColumns = util.retriveLowPValueColumns(XTrain,yTrain)
XTrain,XTest = XTrain[significantColumns],XTest[significantColumns]
thresholdCorrelationColumns = util.retrieveThresholdCorrelationColumns(XTrain,yTrain,rThreshold)
XTrain,XTest = XTrain[thresholdCorrelationColumns],XTest[thresholdCorrelationColumns]

modelGridSearch = util.getBestModel(XTrain,yTrain)

util.printMSE(modelGridSearch,XTrain,XTest,yTrain,yTest)

importanceDF = util.createImportanceDF(modelGridSearch.best_estimator_.feature_importances_,XTrain.columns)

print(importanceDF.head(10))
importanceDF.head(10).plot.barh(x="columns", y="featureImportanceScores", rot=0)
util.displayScatterOfTop10Features(data,importanceDF)





data = util.loadData("NYSE").fillna(0)
dataWithDates = data.copy()
data = data.drop(removalColumns,axis=1)
allData = pd.concat([allData,data.copy()])

y = data["Next10DayReturn"]
X = data.drop("Next10DayReturn",axis=1)
XTrain,XTest,yTrain,yTest = train_test_split(X,y,test_size=0.2,random_state=42)

significantColumns = util.retriveLowPValueColumns(XTrain,yTrain)
XTrain,XTest = XTrain[significantColumns],XTest[significantColumns]
thresholdCorrelationColumns = util.retrieveThresholdCorrelationColumns(XTrain,yTrain,rThreshold)
#XTrain,XTest = XTrain[thresholdCorrelationColumns],XTest[thresholdCorrelationColumns]

modelGridSearch = util.getBestModel(XTrain,yTrain)

util.printMSE(modelGridSearch,XTrain,XTest,yTrain,yTest)

importanceDF = util.createImportanceDF(modelGridSearch.best_estimator_.feature_importances_,XTrain.columns)

print(importanceDF.head(10))
importanceDF.head(10).plot.barh(x="columns", y="featureImportanceScores", rot=0)
util.displayScatterOfTop10Features(data,importanceDF)





data = util.loadData("RUSSELL").fillna(0)
dataWithDates = data.copy()
data = data.drop(removalColumns,axis=1)
allData = pd.concat([allData,data.copy()])

y = data["Next10DayReturn"]
X = data.drop("Next10DayReturn",axis=1)
XTrain,XTest,yTrain,yTest = train_test_split(X,y,test_size=0.2,random_state=42)

significantColumns = util.retriveLowPValueColumns(XTrain,yTrain)
XTrain,XTest = XTrain[significantColumns],XTest[significantColumns]
thresholdCorrelationColumns = util.retrieveThresholdCorrelationColumns(XTrain,yTrain,rThreshold)
XTrain,XTest = XTrain[thresholdCorrelationColumns],XTest[thresholdCorrelationColumns]

modelGridSearch = util.getBestModel(XTrain,yTrain)

util.printMSE(modelGridSearch,XTrain,XTest,yTrain,yTest)

importanceDF = util.createImportanceDF(modelGridSearch.best_estimator_.feature_importances_,XTrain.columns)

print(importanceDF.head(10))
importanceDF.head(10).plot.barh(x="columns", y="featureImportanceScores", rot=0)
util.displayScatterOfTop10Features(data,importanceDF)





data = util.loadData("DJI").fillna(0)
dataWithDates = data.copy()
data = data.drop(removalColumns,axis=1)
allData = pd.concat([allData,data.copy()])

y = data["Next10DayReturn"]
X = data.drop("Next10DayReturn",axis=1)
XTrain,XTest,yTrain,yTest = train_test_split(X,y,test_size=0.2,random_state=42)

significantColumns = util.retriveLowPValueColumns(XTrain,yTrain)
XTrain,XTest = XTrain[significantColumns],XTest[significantColumns]
thresholdCorrelationColumns = util.retrieveThresholdCorrelationColumns(XTrain,yTrain,rThreshold)
XTrain,XTest = XTrain[thresholdCorrelationColumns],XTest[thresholdCorrelationColumns]

modelGridSearch = util.getBestModel(XTrain,yTrain)

util.printMSE(modelGridSearch,XTrain,XTest,yTrain,yTest)

importanceDF = util.createImportanceDF(modelGridSearch.best_estimator_.feature_importances_,XTrain.columns)

print(importanceDF.head(10))
importanceDF.head(10).plot.barh(x="columns", y="featureImportanceScores", rot=0)
util.displayScatterOfTop10Features(data,importanceDF)





allData = allData.fillna(0)
y = allData["Next10DayReturn"]
X = allData.drop("Next10DayReturn",axis=1)
oldThreshold = rThreshold
XTrain,XTest,yTrain,yTest = train_test_split(X,y,test_size=0.2,random_state=42)

significantColumns = util.retriveLowPValueColumns(XTrain,yTrain)
XTrain,XTest = XTrain[significantColumns],XTest[significantColumns]
thresholdCorrelationColumns = util.retrieveThresholdCorrelationColumns(XTrain,yTrain,rThreshold)
XTrain,XTest = XTrain[thresholdCorrelationColumns],XTest[thresholdCorrelationColumns]

modelGridSearch = util.getBestModel(XTrain,yTrain)
"""
#Used to find best threshold
bestThreshold = rThreshold
yTestPredict = modelGridSearch.predict(XTest)
bestScore = mean_squared_error(yTest,yTestPredict)

spread = 0.03 / 2
midpoint = .022
for thresh in np.linspace(midpoint-spread,midpoint+spread,20):
    XTrain,XTest,yTrain,yTest = train_test_split(X,y,test_size=0.2,random_state=42)
    significantColumns = util.retriveLowPValueColumns(XTrain,yTrain)
    XTrain,XTest = XTrain[significantColumns],XTest[significantColumns]
    thresholdCorrelationColumns = util.retrieveThresholdCorrelationColumns(XTrain,yTrain,thresh)
    XTrain,XTest = XTrain[thresholdCorrelationColumns],XTest[thresholdCorrelationColumns]

    modelGridSearch = util.getBestModel(XTrain,yTrain)
    yTestPredict = modelGridSearch.predict(XTest)
    newMSE = mean_squared_error(yTest,yTestPredict)
    if newMSE < bestScore:
        bestThreshold = thresh
        bestScore = newMSE
    
print(bestThreshold)
"""    
util.printMSE(modelGridSearch,XTrain,XTest,yTrain,yTest)

importanceDF = util.createImportanceDF(modelGridSearch.best_estimator_.feature_importances_,XTrain.columns)

print(importanceDF.head(10))
importanceDF.head(10).plot.barh(x="columns", y="featureImportanceScores", rot=0)
util.displayScatterOfTop10Features(allData,importanceDF,False)




